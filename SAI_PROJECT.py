# =============================
# SAI LOCAL AI â€“ STREAMLIT SITE
# Single-file Version
# =============================

import streamlit as st
import uuid
import html

import ollama
import faiss
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# =============================
# Page Config
# =============================
st.set_page_config(
    page_title="SAI Local AI",
    page_icon="ğŸ¤–",
    layout="wide",
)

# =============================
# CSS (Site UI)
# =============================
st.markdown(
    """
    <style>
    body { background-color: #0e1117; color: #e6e6e6; }
    header, footer { visibility: hidden; }

    .chat-user{display:flex;justify-content:flex-end;padding:6px 0}
    .chat-user .bubble{
        background:linear-gradient(135deg,#6c5ce7,#8e7cff);
        color:white;
        padding:14px 18px;
        border-radius:22px 22px 6px 22px;
        max-width:70%;
        word-break:break-word;
    }

    .chat-ai{display:flex;justify-content:flex-start;padding:6px 0}
    .chat-ai .bubble{
        background:#1f2128;
        color:#e5e7eb;
        padding:18px 20px;
        border-radius:22px 22px 22px 6px;
        max-width:72%;
        line-height:1.6;
        word-break:break-word;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# =============================
# Utility
# =============================
def safe(text: str) -> str:
    """XSS ë°©ì–´"""
    return html.escape(text)

# =============================
# Session Init
# =============================
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

if "messages" not in st.session_state:
    st.session_state.messages = []

if "embedder" not in st.session_state:
    st.session_state.embedder = SentenceTransformer("all-MiniLM-L6-v2")

if "faiss_index" not in st.session_state:
    dim = 384
    st.session_state.faiss_index = faiss.IndexFlatL2(dim)
    st.session_state.memory_texts = []

# =============================
# Memory Functions
# =============================
def add_memory(text: str):
    vec = st.session_state.embedder.encode([text]).astype("float32")
    st.session_state.faiss_index.add(vec)
    st.session_state.memory_texts.append(text)

def search_memory(query: str, k: int = 3) -> str:
    if not st.session_state.memory_texts:
        return ""
    qvec = st.session_state.embedder.encode([query]).astype("float32")
    _, idx = st.session_state.faiss_index.search(qvec, k)
    return "\n".join(
        st.session_state.memory_texts[i]
        for i in idx[0]
        if i < len(st.session_state.memory_texts)
    )

def is_repeat(user_input: str, threshold: float = 0.88) -> bool:
    if not st.session_state.memory_texts:
        return False
    vec = st.session_state.embedder.encode([user_input])
    for past in st.session_state.memory_texts[-5:]:
        pvec = st.session_state.embedder.encode([past])
        sim = cosine_similarity(vec, pvec)[0][0]
        if sim > threshold:
            return True
    return False

# =============================
# Local AI Engine (Ollama)
# =============================
def local_ai(user_input: str) -> str:
    related_memory = search_memory(user_input)

    system_prompt = (
        "ê°™ì€ ë‚´ìš©ì„ ë°˜ë³µí•˜ì§€ ë§ê³  ìƒˆë¡œìš´ ê´€ì ìœ¼ë¡œ ë‹µí•˜ë¼."
        if is_repeat(user_input)
        else "ì°¨ë¶„í•˜ê³  ë…¼ë¦¬ì ì¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤."
    )

    prompt = f"""
[ê´€ë ¨ ê¸°ì–µ]
{related_memory}

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_input}

ì¤‘ë³µ ì—†ì´ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µí•˜ë¼.
"""

    res = ollama.chat(
        model="llama3",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt},
        ],
    )

    answer = res["message"]["content"]

    add_memory(user_input)
    add_memory(answer)

    return answer

# =============================
# UI â€“ Header
# =============================
st.title("ğŸ§  SAI Local AI")
st.caption("Streamlit ì‚¬ì´íŠ¸ ì „ìš© Â· ë¡œì»¬ AI Â· ë¡œê·¸ì¸ ì—†ìŒ")

# =============================
# UI â€“ Chat History
# =============================
for m in st.session_state.messages:
    if m["role"] == "user":
        st.markdown(
            f"<div class='chat-user'><div class='bubble'>{safe(m['content'])}</div></div>",
            unsafe_allow_html=True,
        )
    else:
        st.markdown(
            f"<div class='chat-ai'><div class='bubble'>{safe(m['content'])}</div></div>",
            unsafe_allow_html=True,
        )

# =============================
# Input
# =============================
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

if user_input:
    st.session_state.messages.append(
        {"role": "user", "content": user_input}
    )

    with st.spinner("AIê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
        reply = local_ai(user_input)

    st.session_state.messages.append(
        {"role": "assistant", "content": reply}
    )

    # UI ë©”ì‹œì§€ ì œí•œ
    st.session_state.messages = st.session_state.messages[-40:]

    st.rerun()

# =============================
# Footer
# =============================
st.caption("SAIëŠ” ë¹„ì˜ë¦¬ ë¡œì»¬ AI í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.")
